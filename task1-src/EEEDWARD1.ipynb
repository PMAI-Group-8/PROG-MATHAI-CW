{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d48cf2",
   "metadata": {},
   "source": [
    "# Activation function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from layers.activation_functions import ReLU, Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4afa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Z = np.array([\n",
    "    [-2.0, -1.0, 0.0, 1.0, 2.0],\n",
    "    [ 3.0, -3.0, 0.5, -0.5, 0.0]\n",
    "])\n",
    "\n",
    "dA = np.ones_like(Z)   # upstream gradient = 1 everywhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc508525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU forward:\n",
      "[[0.  0.  0.  1.  2. ]\n",
      " [3.  0.  0.5 0.  0. ]]\n",
      "\n",
      "ReLU backward:\n",
      "[[0. 0. 0. 1. 1.]\n",
      " [1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "relu = ReLU()\n",
    "\n",
    "A_relu = relu.forward(Z)\n",
    "dZ_relu = relu.backward(dA)\n",
    "\n",
    "print(\"ReLU forward:\")\n",
    "print(A_relu)\n",
    "\n",
    "print(\"\\nReLU backward:\")\n",
    "print(dZ_relu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9500c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sigmoid forward:\n",
      "[[0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
      " [0.95257413 0.04742587 0.62245933 0.37754067 0.5       ]]\n",
      "\n",
      "Sigmoid backward:\n",
      "[[0.10499359 0.19661193 0.25       0.19661193 0.10499359]\n",
      " [0.04517666 0.04517666 0.23500371 0.23500371 0.25      ]]\n"
     ]
    }
   ],
   "source": [
    "sigmoid = Sigmoid()\n",
    "\n",
    "A_sig = sigmoid.forward(Z)\n",
    "dZ_sig = sigmoid.backward(dA)\n",
    "\n",
    "print(\"\\nSigmoid forward:\")\n",
    "print(A_sig)\n",
    "\n",
    "print(\"\\nSigmoid backward:\")\n",
    "print(dZ_sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e609cf",
   "metadata": {},
   "source": [
    "## Mock Neural Network\n",
    "Forward pass we perform: $$A^{[0]} = X \\leftarrow \\text{input layer}\\\\\n",
    "Z^{[1]} = W^{[1]}A^{[0]} + b^{[1]} \\\\ \n",
    "A^{[1]} = g[Z^{[1]}] = \\text{ReLU}(Z^{[1]}) \\vee \\text{Sigmoid}(Z^{[1]}) \\\\\n",
    "Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]} \\\\\n",
    "A^{[2]} = \\text{Softmax}(Z^{[2]})$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
